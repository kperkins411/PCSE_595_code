{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580c404f-db79-41f3-a901-481143691d3e",
   "metadata": {},
   "source": [
    "# We are going to enter 'Paddy Doctor: Paddy Disease Classification'\n",
    "\n",
    "<a href=\"https://www.kaggle.com/competitions/paddy-disease-classification\">Paddy disease</a> Here is the competition\n",
    "\n",
    "Go to the competition data page and <b>agree to the terms of service</b>. Once you do that you can get data and submit results. At the bottom of the page there is a kaggle CLI link to download the data, after installing the CLI (see below) get this link and run it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe39757-6e56-4f00-ae94-44384449ce31",
   "metadata": {},
   "source": [
    "# Kaggle CLI: Install and set up auth token\n",
    "\n",
    "This makes it really easy to get data and submit results.  Plus it makes it easy to automate tedious stuff (like downloading data)<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d7d87c-d8cd-419c-bab3-020b6dda8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first ensure kaggle is installed\n",
    "#will have to run this everytime unless pip install --user kaggle, but then may run into problems when using ctags to index the fastai user library\n",
    "try:\n",
    "    import kaggle\n",
    "except ModuleNotFoundError:\n",
    "    #not there install\n",
    "    !pip install kaggle\n",
    "\n",
    "#if kaggle is installed but you dont have key installed then importing kaggle will throw an exception\n",
    "#so upload key (verify it's permissions BTW)\n",
    "#to get key- go to Settings-Account-API-Create new Token\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491d4e3d-15bb-428f-bca7-57b09b8ebca6",
   "metadata": {},
   "source": [
    "## Constants and some useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f75b21-4acd-4f5e-9bb4-7e5ae676ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = './train_images'\n",
    "TEST_DIR='./test_images'\n",
    "NUMB_OUTPUT_CLASSES_TO_PREDICT=10\n",
    "DEFAULT_BATCH_SIZE=64\n",
    "DEFAULT_LR=0.001\n",
    "\n",
    "#!pip install pynvml\n",
    "import gc\n",
    "import torch\n",
    "def report_gpu():\n",
    "    print(torch.cuda.list_gpu_processes())\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "report_gpu()\n",
    "\n",
    "#run this in another terminal window to see what is happenning \n",
    "#to your gpu memory(assumming you have one).  It will update every 2 seconds\n",
    "#watch nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13987134-ee71-4cad-9587-820d15212b34",
   "metadata": {},
   "source": [
    "defaults, if not using all GPU memory increate batch size and learningrate<br>\n",
    "Rule of thumb: if double bs multiply lr by 1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c13960-d2bf-4414-b475-1cd44e1e05eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=DEFAULT_BATCH_SIZE*2\n",
    "lr=DEFAULT_LR*1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26207c50-b92d-40d2-b866-bf42024dbe72",
   "metadata": {},
   "source": [
    "## Kaggle CLI: Get the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b3f332-8ca3-44ca-aa58-ae56183fd595",
   "metadata": {},
   "outputs": [],
   "source": [
    "#download data once\n",
    "import os\n",
    "if not os.path.exists(TRAIN_DIR):\n",
    "    #get the data\n",
    "    !kaggle competitions download -c paddy-disease-classification\n",
    "    \n",
    "    #unzip it, -q is silent\n",
    "    !unzip -q paddy-disease-classification.zip\n",
    "    \n",
    "    #remove orig zip file (because its large)\n",
    "    !rm paddy-disease-classification.zip\n",
    "\n",
    "    #it put it all in /notebooks, thats fine if you dont mind importing it every time you start a machine \n",
    "    #(it's pretty fast though so why not?) Otherwise move it to storage and symlink it back, if you do this \n",
    "    #keep in mind you are permanetly taking up 1GB of your allocated 20GB of space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedacb52-44bf-4e6f-a2eb-540dce39efca",
   "metadata": {},
   "source": [
    "## Explore data\n",
    "\n",
    "Notice that train_images has 10 folders, each with a picture of rice with a type of disease\n",
    "<br><b>But test_images has no folders. That's because you have to determine which label to apply to each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2ac4dc-c5d0-4804-a434-16e25c9e46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is train.csv?\n",
    "import pandas as pd\n",
    "df =pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8811c751-bdc5-4647-aefd-95b104b78c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#it has a list of all the training files and their labels\n",
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "648cf568-b02a-438a-a203-60689c54d2ae",
   "metadata": {},
   "source": [
    "The dataset is imbalanced, easy to address (use a weighted dataloader in training) but beyond the scope of this course\n",
    "\n",
    "Variety and age both have usefull info, but using them will complicate our model quite a bit, so we will ignore them for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a14908-8cae-4478-842e-97f98191db0a",
   "metadata": {},
   "source": [
    "### Turns out some of the images are different sizes, each batch has to have images the same size\n",
    "\n",
    "see what the sizes are and remove the (640,480) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596cfc92-64f0-41c5-966a-78a1130736df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from fastai.basics import *\n",
    "from fastai.vision.all import *\n",
    "from fastai.callback.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad98ed2-67b8-4f65-a460-fecca5690ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.parallel import *\n",
    "\n",
    "fls=get_image_files(TRAIN_DIR)\n",
    "def f(o): return PILImage.create(o).size\n",
    "sizes = parallel(f, fls, n_workers=6)\n",
    "pd.Series(sizes).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a60665-8ed0-4f63-b456-ffdebf3fb4ee",
   "metadata": {},
   "source": [
    "### Remove them?  We could but what if the test set also has different sizes (it does)\n",
    "\n",
    "Lets just resize them when needed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deddd641-5de6-4636-8c89-b0dfc4e952ae",
   "metadata": {},
   "source": [
    "## OK Lets build a model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea793d0-6107-4d79-811c-4ca221489d14",
   "metadata": {},
   "source": [
    "### First load the Data\n",
    "\n",
    "Accomplished using dataloaders, a dataloader boils down to 2 parts: a dataset and a Dataset stores the samples and their corresponding labels, and DataLoader wraps an iterable around the Dataset to enable easy access to the samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a8dc68-a17d-4cb5-8417-9b228d389532",
   "metadata": {},
   "source": [
    "#### BTW Experimenting goes much (MUCH!) faster if you use a subset of original data\n",
    "\n",
    "How about 50 of each?  Dataset size is roughly 100 then.  Not the same distribution as original dataset but faster to verify that things are working before we actually commit to the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd4dc2f-2c18-4cd4-a124-eab0d3625342",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets get 50 of each type\n",
    "new_df = df.groupby('label').sample(n=50)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe00734-9d0d-4516-aa6d-b2bb37027942",
   "metadata": {},
   "source": [
    "#### Method 1- Load all data (using file system)\n",
    "\n",
    "dataloaders are flexible, here I'm telling it where the images are and each folder name will be interpreted as the contained images label.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a1d1a0-0484-4dff-ba96-4d3487cc97b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you dont have a valid_pct then you get a Nonetype object is non iterable error\n",
    "# dls=ImageDataLoaders.from_folder('/notebooks/train_images',valid_pct=0.2)\n",
    "dls=ImageDataLoaders.from_folder('/notebooks/PCSE_595_code/train_images',valid_pct=0.2,bs=bs,item_tfms=Resize(480, method='squish'),\n",
    "    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n",
    "# # dls.show_batch()\n",
    "# dls.train_ds.items[:3]\n",
    "\n",
    "#if you want to get rid of\n",
    "# del(dls)\n",
    "# report_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92650045-f98e-426d-a1e5-05e0804288ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.show_batch()\n",
    "# dls.train_ds.items[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409dd2a7-dcf8-42f6-b152-c3630df92911",
   "metadata": {},
   "source": [
    "#### Method 2- Load all data using the .csv file\n",
    "\n",
    "Maybe use a smaller dataset to verify training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30ebf0f-12f8-4ca8-9057-59d63df39d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a new column which indicates where each image is located in TRAIN_DIR\n",
    "df[\"loc\"] = df['label'].astype(str) +\"/\"+ df[\"image_id\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a065d1ba-7d24-4bb5-983d-abe780c6a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when satisfied that things are set up properly, train on full dataset(df) instead of new_df\n",
    "dls = ImageDataLoaders.from_df(df=df, #df=new_df or df\n",
    "                               path=TRAIN_DIR, \n",
    "                               fn_col=4,\n",
    "                               label_col=1,\n",
    "                               suff='', #do not add extra .jpg\n",
    "                               folder=\".\",\n",
    "                               bs=bs,\n",
    "                              valid_pct=0.2,item_tfms=Resize(480, method='squish'),\n",
    "    batch_tfms=aug_transforms(size=128, min_scale=0.75))\n",
    "# dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6daae7-4776-4828-932c-7623192a210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean up any memory that we can\n",
    "report_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fa7cee-8611-409d-8ac6-b27640f84e8c",
   "metadata": {},
   "source": [
    "### Next Choose a timm Model to Fine Tune\n",
    "\n",
    "Which one though?  Look at <a href=\"https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning\">The best vision models for fine-tuning</a>.  This notebook compares many different models which are fine-tuned on two differnt datasets;  <a href=\"https://www.robots.ox.ac.uk/~vgg/data/pets/\"> Oxford IIT-Pet</a> and then <a href=\"https://www.kaggle.com/c/planet-understanding-the-amazon-from-space/data\">Kaggle planet (space images)</a>.  \n",
    "\n",
    "<mark>Choose a model with a low error rate and fit time (trains faster) on the type of data you are using.</mark>  For instance, if you want to build a dogs verses cats classifier, then choose a model that performed well when fine tuned on <a href=\"https://www.robots.ox.ac.uk/~vgg/data/pets/\"> Oxford IIT-Pet</a>.\n",
    "\n",
    "<b>BTW You want a pretrained model to fine tune on, so just look at the pretrained ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2324c79-5814-4138-ad0b-c05bdeadf48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what \n",
    "import timm\n",
    "# timm.list_models(pretrained=True)  #all models\n",
    "timm.list_models(['*convnext_tiny*'],pretrained=True)  #pretrained convnext models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76be424-0eaf-41eb-bb37-8af161b13c43",
   "metadata": {},
   "source": [
    "### Now train the model\n",
    "\n",
    "The model is wrapped in a learner object which also takes our dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10804a7-5183-44c8-bf93-c36ce85f97da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use vim -t vision_learner to see where fastai creates either a timm or a pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e589329-04b9-4407-bfce-c30fd6576705",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this learner will use pytorches convnext_tiny (type convnext_tiny?? in cell to get location)\n",
    "# learn = vision_learner(dls, convnext_tiny, metrics=error_rate, path='.')\n",
    "\n",
    "#this learner will use timms convnext_tiny model\n",
    "learn = vision_learner(dls, 'convnext_tiny',lr=lr, metrics=error_rate, path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017e78ab-baac-4b9f-bcfc-cc6d85ff407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.fine_tune(5)\n",
    "# learn.fit_one_cycle(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cbb0c4-fd50-45ae-922f-0e0aeaef4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check out what is happenning to GPU memory (watch nvidia-smi) is it being used?\n",
    "#if we have a lot of extra memory then increase the batch size to increase training speed\n",
    "#(rule of thumb: also increase learning rate by roughly square root of the batch size multiplier\n",
    "# so if you quadruple batch size, multiply learning rate by 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d5d3a7-5890-46cb-972d-9c9919a87231",
   "metadata": {},
   "source": [
    "### Can we optimize anything? Speed stuff up?\n",
    "\n",
    "see how much gpu is being used nvidia-smi\n",
    "\n",
    "how much memory is being used (install htop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a5d3c5-0cbd-4ce3-9544-919a9bd1422a",
   "metadata": {},
   "source": [
    "turns out we are not really using much of our GPU, lets double the batch size and 1.4*lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba45a65-e3fc-4163-8bf1-f417355eee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'current batch size={learn.data.bs}, current learning rate={learn.lr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9931658b-5ff6-42da-a3a0-6986d81be8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#increase batch size of images to go to the gpu at a time\n",
    "learn.data.bs=learn.data.bs*2\n",
    "\n",
    "#increase model learning rate\n",
    "learn.lr=learn.lr*1.4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13728173-2d90-4d40-8330-5496c1207aec",
   "metadata": {},
   "source": [
    "### Save model for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f463c6e9-0b89-4d13-95cb-f1ac2e1e042c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#just save the model to weights dir (its pretty big)\n",
    "#want to see how it works? Go to def of save (vim -t save) and find where it actualy saves the model (save_model function) \n",
    "learn.save('weights_only', with_opt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d68ac5-f8af-4126-8e21-071ea8f3c130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learn.load('weights_only', with_opt=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193be2db-c5b6-4cff-9b2c-d2bcb39dc5ab",
   "metadata": {},
   "source": [
    "### Use model to generate submission\n",
    "\n",
    "Note: This part comes from  <a href=\"https://www.kaggle.com/code/jhoward/first-steps-road-to-the-top-part-1\">First Steps: Road to the Top, Part 1</a>.  An excellent series showing increasingly better submissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20add34-be70-4bf3-8c15-fe9f8443461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first what does ss look like\n",
    "ss = pd.read_csv('./sample_submission.csv')\n",
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6b730bb-73c1-442d-b76e-95b34a202369",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the test files\n",
    "tst_files = get_image_files(TEST_DIR).sorted()\n",
    "tst_dl = dls.test_dl(tst_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054f185e-1931-456b-9702-ea3d0ef157f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now get the probabilities of each class, and the index of the most likely class, from this test set (the 2nd thing returned by get_preds are the targets, which are blank for a test set, so we discard them):\n",
    "probs,_,idxs = learn.get_preds(dl=tst_dl, with_decoded=True)\n",
    "idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c9bd29-836c-4bd0-817a-edde5f48c887",
   "metadata": {},
   "source": [
    "These need to be mapped to the names of each of these diseases, these names are stored by fastai automatically in the vocab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb188e-b787-4f13-b29f-b269104a2b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "dls.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d38a68-8305-4434-92f3-f62f52065e35",
   "metadata": {},
   "source": [
    "We can create an apply this mapping using pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572e1f1-0113-4169-87b0-670805d08fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = dict(enumerate(dls.vocab))\n",
    "results = pd.Series(idxs.numpy(), name=\"idxs\").map(mapping)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd7cc02-d89e-4363-ab3d-f0b41f96b9bb",
   "metadata": {},
   "source": [
    "Kaggle expects the submission as a CSV file, so let's save it, and check the first few lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7d6d40-d245-4fc0-976d-03a3da175135",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['label'] = results\n",
    "ss.to_csv('subm.csv', index=False)\n",
    "!head subm.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5800ac7-ff8c-4237-a81a-6c4effddd658",
   "metadata": {},
   "source": [
    "### Zip And Upload to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca43f06f-b7c5-4473-aff3-c3813050f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip ./subm.zip ./subm.csv\n",
    "!kaggle competitions submit -c paddy-disease-classification -f subm.zip -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f043cbe6-de73-4016-8e68-b674b2d31695",
   "metadata": {},
   "source": [
    "## TestBed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba58de21-17f1-405d-a07a-8ca3171976b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE if you run the model below you will get a runtime error that says at least 2 tensors are not the same size\n",
    "#lets see what the sizes are\n",
    "\n",
    "# from collections import defaultdict\n",
    "# szs=defaultdict(int)\n",
    "# for fle in tqdm(fls):\n",
    "#     szs[Image.open(fle).size]+=1\n",
    "# szs\n",
    "\n",
    "#delete the few missized images\n",
    "# import os\n",
    "# for fle in tqdm(fls):\n",
    "#     if( Image.open(fle).size == (640,480)):\n",
    "#         os.remove(fle)\n",
    "\n",
    "#NOTE if you leave the data in the notebooks folder then its permanant so \n",
    "# YOU ONLY HAVE TO RUN THIS EVERY TIME YOU DOWNLOAD THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aec1afc-64a7-4f0a-a1e2-1c2b71255757",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
